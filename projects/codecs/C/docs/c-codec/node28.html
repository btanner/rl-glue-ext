<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>Agent Step</TITLE>
<META NAME="description" CONTENT="Agent Step">
<META NAME="keywords" CONTENT="c-codec">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="c-codec.css">

<LINK REL="next" HREF="node29.html">
<LINK REL="previous" HREF="node27.html">
<LINK REL="up" HREF="node25.html">
<LINK REL="next" HREF="node29.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A NAME="tex2html458"
  HREF="node29.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next"
 SRC="file:/sw/share/lib/latex2html/icons/next.png"></A> 
<A NAME="tex2html454"
  HREF="node25.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up"
 SRC="file:/sw/share/lib/latex2html/icons/up.png"></A> 
<A NAME="tex2html448"
  HREF="node27.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous"
 SRC="file:/sw/share/lib/latex2html/icons/prev.png"></A> 
<A NAME="tex2html456"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents"
 SRC="file:/sw/share/lib/latex2html/icons/contents.png"></A>  
<BR>
<B> Next:</B> <A NAME="tex2html459"
  HREF="node29.html">Agent End</A>
<B> Up:</B> <A NAME="tex2html455"
  HREF="node25.html">Essential Components Of A</A>
<B> Previous:</B> <A NAME="tex2html449"
  HREF="node27.html">Agent Start</A>
 &nbsp; <B>  <A NAME="tex2html457"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->

<H3><A NAME="SECTION00061300000000000000">
Agent Step</A>
</H3>
The agent_step function encodes the heart of the agents' learning algorithm and action selection mechanism. At a minimum the step function must return an action every time it is called. In most learning agents, the step function queries the agent programs action selection function and performs a learning update based on the input observation and reward. The following agent_step function does a SARSA update on a tabular value function Q:
<PRE><TT>
1. agent_step(reward, observation) <IMG
 WIDTH="22" HEIGHT="16" ALIGN="BOTTOM" BORDER="0"
 SRC="img1.png"
 ALT="$\rightarrow$"> action
<BR>
2. 		newAction = egreedy(observation)
<BR>
3. 		 QofOld = Q(oldState,oldAction)
<BR>
4. 		 QofNew = Q(observation,newAction) 
<BR>
5. 		 V(oldState,oldAction) = VofOld + <IMG
 WIDTH="15" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img3.png"
 ALT="$\alpha$">[reward + <IMG
 WIDTH="14" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img4.png"
 ALT="$\gamma$">VofNew - VofOld]
<BR>
6. 		 oldState = observation
<BR>
7.		 oldAction = newAction
<BR>
8. 		 <B>set</B> action equal to newAction
<BR>
9. <B>return</B> action
</TT></PRE>  
Notice that the agent program must explicitly store the observation and action from the previous time step. RL-Glue does not make the history of actions, observations and rewards available to the agent or environment.

<P>
<BR><HR>
<ADDRESS>
Brian Tanner
2008-09-27
</ADDRESS>
</BODY>
</HTML>
